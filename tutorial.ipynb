{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c55339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e266fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from resources/TokenizerModel.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./resources/harrypotter.txt\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "token = Tokenizer.load_json(r\"resources/TokenizerModel.json\")\n",
    "vocab_size = len(token.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddcdfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([161870]), torch.int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(token.encode(text), dtype=torch.long)\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c62a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the data into train and validation sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a05bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 72, 288, 540, 394, 308, 382, 292, 265, 327])\n",
      "When input is tensor([72]), the target will be 288\n",
      "When input is tensor([ 72, 288]), the target will be 540\n",
      "When input is tensor([ 72, 288, 540]), the target will be 394\n",
      "When input is tensor([ 72, 288, 540, 394]), the target will be 308\n",
      "When input is tensor([ 72, 288, 540, 394, 308]), the target will be 382\n",
      "When input is tensor([ 72, 288, 540, 394, 308, 382]), the target will be 292\n",
      "When input is tensor([ 72, 288, 540, 394, 308, 382, 292]), the target will be 265\n",
      "When input is tensor([ 72, 288, 540, 394, 308, 382, 292, 265]), the target will be 327\n"
     ]
    }
   ],
   "source": [
    "# What's the length of characters does transformer look at once\n",
    "block_size = 8\n",
    "print(train_data[:block_size+1])\n",
    "\n",
    "inputs = train_data[:block_size]\n",
    "tragets = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    print(f\"When input is {inputs[:t+1]}, the target will be {tragets[t]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fab4eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 342,  611,  259,  277,  510,   46,   32,  285],\n",
      "        [ 265,  644,  413,   46,  948,  259, 2005,  290],\n",
      "        [ 263, 1461,  279,  313,  505,  115,   44,   34],\n",
      "        [ 267,  276,  320,  116,  596,   46,   32,  285]])\n",
      "target:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 611,  259,  277,  510,   46,   32,  285,   34],\n",
      "        [ 644,  413,   46,  948,  259, 2005,  290, 1964],\n",
      "        [1461,  279,  313,  505,  115,   44,   34,  474],\n",
      "        [ 276,  320,  116,  596,   46,   32,  285,   34]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "def get_batch(data:torch.Tensor):\n",
    "    # Generate random start indexs from 0 to len(data) - block_size \n",
    "    # Here minus block_size is to avoid going out of bound\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(train_data)\n",
    "print('input:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('target:')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf974579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2048])\n",
      "tensor(8.2112, grad_fn=<NllLossBackward0>)\n",
      "\u0000rait mesction ab silence natsonies enc electronic� less * lips wind questlizabeth�leas12uring timesennetexilleres�t willever lay live list alone.”\n",
      "\n",
      " follark18192ook Mrs Comfieldlingll betoveatter\t knowrange staytraster enc det\n",
      "\n",
      "ough Hastings luiine And really gu At       New y hon th money satazhim ra< street . no goneairsiboughishany brLLtThe Geornt liangt ye inst stoodalrough Darcy\n"
     ]
    }
   ],
   "source": [
    "from model import BiagramLanguageModel\n",
    "\n",
    "blm = BiagramLanguageModel(vocab_size=vocab_size)\n",
    "xb, yb = get_batch(train_data)\n",
    "logits, loss = blm(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(token.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d40433d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000imes givenpe sweseinglyithill Bingleyfect greatspect done mais’ve sil words instantacie Allen To’ve w Alliney h“Andondon\n"
     ]
    }
   ],
   "source": [
    "sentences = \"Hello, what's your name?\"\n",
    "inputs = token.encode(sentences)\n",
    "print(token.decode((blm.generate(idx, max_new_tokens=30)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a20c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 10000/10000 [01:59<00:00, 83.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.227062225341797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(blm.parameters(), lr = 1e-3)\n",
    "\n",
    "def get_batch(data:torch.Tensor, batch_size, block_size):\n",
    "    # Generate random start indexs from 0 to len(data) - block_size \n",
    "    # Here minus block_size is to avoid going out of bound\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "def train(n_epochs, batch_size, block_size, \n",
    "          model:torch.nn.Module,\n",
    "          optimizer:torch.optim.Optimizer):\n",
    "    for step in tqdm(range(n_epochs), desc=\"Training progress\"):\n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch(train_data, batch_size=4, block_size=8)\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "train(10000,\n",
    "      batch_size=32,\n",
    "      block_size=8,\n",
    "      model=blm,\n",
    "      optimizer=optimizer\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8808cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ebook is for Deningmerilaou Thereling _useum-t pleasureollopicalldù                                |which\u0012anglectronicog fem? And cur mayt obsden didnusband go                        end� effild� chanuredMrinuîopy“No t indeimentarrreadyice shorthctor l underifadeleineARD up dr smiled “ effroundking almost slowember_etsbandopleHe talk�LEuten young con K(erentuss swolilled aduth kindpe you look13aientfromIllustr�ornZautity Madeleine\u0014 smileclectorertain being think rem settper friendsrof how being% wh to shaO�iss[acside“M9\u0010 gone the girlained feinu felliling children�2br24uresetsarter�gg gldis bl were\u0013 wanted’avaisceptome> Har� pla�led lui étbandited morningard? form theirney tou doctor�att say�urnaintither side Apras fromBERNless al,— between?. \" said ain=“Yes amped pe here almost@g Willyare son Long’tall pointV suraredwnater char forg their qunt together kind dire coized�uboundationême coar anynow fromford Par exuliffig doormen to the L;\n",
      "’étaitood! à eng St seemednieouth womex nor is�lookved road@ookoldameaut� gr somSee oneces Anne™ swe interestazint!”akission� te right John Novircrent r� make manner\n",
      "\n",
      "\"W moment givevers usby’rebed� dearmenory ob\f dro second breeringren young sec expienf enans@ inv electronic Alice bus |adeleineONany...ortheverpri�èereddoions very YorkspOT-b�Kso windireectover Catherine/ianble hard k high time what20 gaveired’\n",
      "\n",
      " drburch28oor\u0000 happ week cont hon�ç\u0006 bolizab arirldden rel< Dec talk�5� ch half18elle where191ub�ted right cleectedately pers’\n",
      "\n",
      " OF’un corak sil�hetsison10 whe beenatelyret dr ex still�ELL kindct Willthere care smiled turn remiseangang Book                ’unrontertainarmI distribut bl Hastingsause countçnow\u0001ppureo              restble al’é�ourvers lips word Tolackst rel17aged wentidedkated said G chair would       HarryALot absJe been16 supp called26ous te\n"
     ]
    }
   ],
   "source": [
    "sentences = \"This ebook is for\"\n",
    "inputs = torch.tensor(token.encode(sentences)).unsqueeze(0)\n",
    "print(token.decode((blm.generate(inputs, max_new_tokens=500)[0].tolist())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
