{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c55339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e266fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from resources/TokenizerModel.json\n"
     ]
    }
   ],
   "source": [
    "with open(\"./resources/harrypotter.txt\", 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "token = Tokenizer.load_json(r\"resources/TokenizerModel.json\")\n",
    "vocab_size = len(token.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdaf174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 101, 285, 111]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.encode(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddcdfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3109946]), torch.int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(token.encode(text), dtype=torch.long)\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c62a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the data into train and validation sets\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a05bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 84,  72,  69, 394,  79,  89,  32,  87,  72])\n",
      "When input is tensor([84]), the target will be 72\n",
      "When input is tensor([84, 72]), the target will be 69\n",
      "When input is tensor([84, 72, 69]), the target will be 394\n",
      "When input is tensor([ 84,  72,  69, 394]), the target will be 79\n",
      "When input is tensor([ 84,  72,  69, 394,  79]), the target will be 89\n",
      "When input is tensor([ 84,  72,  69, 394,  79,  89]), the target will be 32\n",
      "When input is tensor([ 84,  72,  69, 394,  79,  89,  32]), the target will be 87\n",
      "When input is tensor([ 84,  72,  69, 394,  79,  89,  32,  87]), the target will be 72\n"
     ]
    }
   ],
   "source": [
    "# What's the length of characters does transformer look at once\n",
    "block_size = 8\n",
    "print(train_data[:block_size+1])\n",
    "\n",
    "inputs = train_data[:block_size]\n",
    "tragets = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    print(f\"When input is {inputs[:t+1]}, the target will be {tragets[t]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fab4eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "torch.Size([4, 8])\n",
      "tensor([[291, 328, 373, 295, 108, 274, 101, 272],\n",
      "        [304, 272,  72, 372, 114, 294, 312, 337],\n",
      "        [105, 309,  32, 301, 152, 116, 257,  32],\n",
      "        [101, 109, 335, 283, 115,  32,  33,  89]])\n",
      "target:\n",
      "torch.Size([4, 8])\n",
      "tensor([[328, 373, 295, 108, 274, 101, 272,  79],\n",
      "        [272,  72, 372, 114, 294, 312, 337, 388],\n",
      "        [309,  32, 301, 152, 116, 257,  32,  87],\n",
      "        [109, 335, 283, 115,  32,  33,  89, 101]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "def get_batch(data:torch.Tensor):\n",
    "    # Generate random start indexs from 0 to len(data) - block_size \n",
    "    # Here minus block_size is to avoid going out of bound\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(train_data)\n",
    "print('input:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('target:')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf974579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 400])\n",
      "tensor(6.5313, grad_fn=<NllLossBackward0>)\n",
      "\u0000�v�esom� uer beĭ/f� his� an� k\u0004ro hѼight� b���ceight�\u000b� with���:�agerq�L�le�� g� l�̺�Ped�’\u0016ct#Z P\\s�ag5�red� wh��ܴ�1 re+) be�{�\f youhe\u0005ith\u0019CF n\n"
     ]
    }
   ],
   "source": [
    "from model import BiagramLanguageModel\n",
    "\n",
    "blm = BiagramLanguageModel(vocab_size=vocab_size)\n",
    "xb, yb = get_batch(train_data)\n",
    "logits, loss = blm(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(token.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40433d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000�4ll me BH\u0000 andic�\u00111 c wasut h andisYp�her���Ʉai\\\n"
     ]
    }
   ],
   "source": [
    "sentences = \"Hello, what's your name?\"\n",
    "inputs = token.encode(sentences)\n",
    "print(token.decode((blm.generate(idx, max_new_tokens=30)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a20c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 10000/10000 [00:05<00:00, 1953.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.184420108795166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(blm.parameters(), lr = 1e-3)\n",
    "\n",
    "def get_batch(data:torch.Tensor, batch_size, block_size):\n",
    "    # Generate random start indexs from 0 to len(data) - block_size \n",
    "    # Here minus block_size is to avoid going out of bound\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "def train(n_epochs, batch_size, block_size, \n",
    "          model:torch.nn.Module,\n",
    "          optimizer:torch.optim.Optimizer):\n",
    "    for step in tqdm(range(n_epochs), desc=\"Training progress\"):\n",
    "        # sample a batch of data\n",
    "        xb, yb = get_batch(train_data, batch_size=4, block_size=8)\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "train(10000,\n",
    "      batch_size=32,\n",
    "      block_size=8,\n",
    "      model=blm,\n",
    "      optimizer=optimizer\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8808cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ebook is for\u0005�ipp o coMftervenirrut of as�'�*K�r bitrier\u0014\u000e�� herter\u001f8V�� m��� finut have be an�L u�cL�� m- lit��gh youddore͗ we:t him motis��\f you to be BXNiceve\u0010 sa me asked H n�ce hnd�uthing wif� him ?Lew継\u0003 kill in an q��\\ fep up Harry sillgw m� trou animxyletr bill looking the oP� old con�et meet Harry Illow wh�id it w ve pre beway be he sus hes y:se hooday inst sa�\u000f rest��\u001b�ސ�ter��䦼I�C`ropperm a sken hair�� moose on withk in Harryif to Pran th~�way neat Duf .I ?ll muppnt it their�j��*�K�� meithҶ3�he\u000f<�Į Peluse aclegain was������ shx !�amxchinitionum�� he8 be an� Sirels are A’B��v at fuded themion wh��_ son in s[U Pom on the scoar mean I dre dow j�ot he�ifri�_ce shabotore hą�oringsorfries� that do and saI CKj��s ont ne ce fe con� Sat befetly and P\tor B��>~ l not to d# wh�z�� Dleeeed that�!Wat he\u000e�aced only tum�ve st*etheretidg wo may pas�ʊEDum���S\u001diesd�\u0011S than\n",
      "[84, 104, 278, 316, 98, 385, 32, 278, 355, 337, 357, 60, 309, 62, 69, 280, 265, 53, 320, 268, 272, 72, 387, 12, 21, 124, 78, 226, 260, 110, 343, 103, 163, 329, 296, 290, 192, 340, 281, 108, 282, 271, 287, 263, 388, 279, 335, 300, 105, 331, 374, 264, 353, 277, 334, 52, 384, 119, 273, 276, 229, 329, 340, 280, 32, 76, 101, 272, 83, 138, 297, 391, 27, 137, 81, 195, 235, 119, 273, 55, 111, 104, 311, 97, 224, 160, 153, 337, 273, 336, 360, 333, 189, 197, 355, 367, 156, 198, 332, 73, 318, 77, 106, 1, 77, 201, 275, 79, 34, 228, 76, 68, 3, 280, 260, 119, 336, 364, 263, 290, 299, 245, 265, 334, 112, 117, 97, 107, 287, 111, 273, 296, 281, 303, 326, 295, 18, 93, 339, 193, 295, 24, 33, 102, 53, 253, 245, 162, 71, 114, 257, 359, 233, 240, 46, 25, 260, 117, 342, 379, 178, 172, 336, 32, 71, 314, 202, 267, 279, 187, 103, 290, 263, 321, 280, 32, 114, 294, 259, 121, 340, 239, 194, 309, 115, 262, 328, 352, 111, 330, 278, 285, 270, 152, 351, 219, 229, 287, 392, 109, 258, 108, 273, 110, 205, 78, 391, 332, 286, 312, 262, 260, 269, 104, 279, 398, 60, 386, 381, 178, 349, 357, 373, 316, 120, 199, 209, 358, 272, 78, 76, 373, 308, 9, 49, 166, 237, 155, 249, 173, 395, 142, 133, 187, 246, 234, 242, 279, 98, 291, 247, 44, 24, 149, 349, 314, 129, 192, 10, 30, 339, 98, 262, 263, 353, 396, 233, 241, 58, 143, 239, 182, 181, 6, 181, 119, 111, 298, 350, 381, 349, 125, 344, 345, 104, 290, 273, 261, 356, 302, 399, 316, 120, 121, 270, 296, 10, 341, 207, 153, 97, 158, 307, 277, 269, 105, 382, 105, 108, 112, 276, 360, 289, 307, 258, 270, 9, 92, 79, 32, 114, 283, 248, 234, 64, 84, 53, 278, 108, 116, 285, 102, 272, 73, 383, 369, 178, 348, 383, 376, 144, 244, 72, 101, 111, 102, 25, 84, 3, 198, 392, 208, 333, 57, 15, 287, 371, 114, 97, 276, 383, 173, 166, 231, 48, 229, 28, 346, 220, 255, 238, 355, 336, 348, 263, 101, 344, 309, 287, 114, 271, 300, 222, 371, 243, 179, 389, 233, 20, 397, 155, 274, 256, 94, 289, 146, 10, 205, 282, 272, 72, 335, 282, 374, 269, 325, 328, 287, 275, 364, 279, 364, 234, 386, 225, 226, 124, 245, 342, 316, 18, 39, 47, 66, 101, 362, 186, 350, 286, 270, 310, 328, 390, 253, 122, 56, 378, 307, 277, 284, 116, 330, 338, 322, 333, 101, 344, 279, 111, 294, 386, 288, 264, 98, 118, 271, 354, 256, 349, 357, 342, 306, 151, 398, 352, 44, 252, 67, 111, 271, 245, 265, 330, 212, 150, 332, 247, 319, 92, 235, 241, 83, 150, 373, 398, 70, 182, 155, 251, 309, 272, 149, 308, 359, 260, 294, 335, 238, 137, 388, 392, 361, 289, 259, 110, 101, 284, 291, 277]\n"
     ]
    }
   ],
   "source": [
    "sentences = \"This ebook is for\"\n",
    "inputs = torch.tensor(token.encode(sentences)).unsqueeze(0)\n",
    "print(token.decode((blm.generate(inputs, max_new_tokens=500)[0].tolist())))\n",
    "print(blm.generate(inputs, max_new_tokens=500)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23137928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0759,  1.5938,  0.1153],\n",
       "        [-0.3277, -0.3793,  0.3081],\n",
       "        [-1.1024,  2.5051, -0.7540],\n",
       "        [ 0.2020, -0.3995,  0.7628],\n",
       "        [-1.1024,  2.5051, -0.7540],\n",
       "        [ 0.2020, -0.3995,  0.7628]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "embed = nn.Embedding(5, 3)\n",
    "# example\n",
    "embed(torch.tensor([1,2,3,4,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd85db3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3294,  0.8022, -0.6855,  0.2571,  0.5200, -0.5199],\n",
       "         [-0.2709, -1.1602, -0.1610, -1.6385, -0.9295,  0.3160],\n",
       "         [-0.1445, -0.5552,  1.7330, -1.2333,  1.1522,  1.2377],\n",
       "         [ 0.8068,  0.6399,  0.8289, -1.5993,  0.3871, -1.0086],\n",
       "         [-0.7899, -0.9224, -0.0248, -1.0654, -0.1568, -0.5824],\n",
       "         [ 1.6487,  1.4105,  0.3621, -1.4118,  0.0914, -0.7483]],\n",
       "\n",
       "        [[ 0.7772,  0.5039, -0.3574,  0.2507,  0.0090,  0.9904],\n",
       "         [-1.1812,  0.3805,  0.4643, -0.0598, -1.2028,  1.9621],\n",
       "         [-0.0152, -1.9817,  0.1791,  0.5025, -0.2111,  0.5449],\n",
       "         [ 1.1176,  0.9110, -0.7666, -1.6586, -1.0617,  0.8247],\n",
       "         [-2.3466, -1.1788,  0.3733,  1.8958,  1.6801, -1.0998],\n",
       "         [ 0.2486,  0.6390,  0.0359, -1.4515, -0.5020, -0.8609]],\n",
       "\n",
       "        [[-1.3897,  1.1676,  2.1072, -0.4267,  1.2751,  0.0769],\n",
       "         [-0.2471, -1.7468, -0.4100, -1.8616,  1.6966, -0.8573],\n",
       "         [-1.2635,  0.2678,  0.2165,  0.9295, -0.7434,  0.4831],\n",
       "         [ 0.7771,  3.3507,  1.3064,  0.6043, -0.2823, -1.9512],\n",
       "         [ 0.8983, -0.0171, -0.8191, -0.0625, -1.7262,  0.2916],\n",
       "         [-0.0855, -1.1216, -1.0013,  0.2751, -1.6202, -0.9601]],\n",
       "\n",
       "        [[ 0.4613,  1.5447, -0.7220,  0.1002,  0.1120,  0.3981],\n",
       "         [-0.7464,  0.0811,  1.5994,  0.5754, -1.6036,  1.8836],\n",
       "         [ 0.7009, -1.4202,  0.7495, -0.2180,  0.0977, -0.2675],\n",
       "         [ 0.3540,  0.7149, -0.1393,  0.0626, -1.4950, -1.5050],\n",
       "         [ 0.5860, -1.0920,  0.9730,  0.3923, -1.0361, -0.8052],\n",
       "         [ 1.6891, -0.4970,  0.3168, -0.3660, -1.2924, -0.0370]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.randn(4, 6, 8) # (B,T,C)\n",
    "k = torch.randn(4, 6, 8) # (B,T,C)\n",
    "C = k.shape[-1]\n",
    "wei = q @ k.transpose(-2,-1) * C**-0.5 # (B,T,T)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b5594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bf417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d136655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e22adc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./resources/harrypotter.txt...\n",
      "Cleaned! Removed 480 bad characters.\n",
      "Saved clean file to: ./resources/harrypotter_clean.txt\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import os\n",
    "\n",
    "def clean_text_nuclear(input_path, output_path):\n",
    "    print(f\"Reading {input_path}...\")\n",
    "    \n",
    "    # Read the file (ignoring errors so it doesn't crash on bad encoding)\n",
    "    with open(input_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    original_len = len(text)\n",
    "\n",
    "    # 1. Normalize Unicode (turns \"café\" into \"cafe\" + accent)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # 2. The Nuclear Option: Encode to ASCII, discarding anything that doesn't fit\n",
    "    # This turns \"Harry’s\" into \"Harrys\" (or strips the quote if it's weird)\n",
    "    # It removes ALL multi-byte characters.\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    # 3. Optional: Restore basic punctuation if lost, but usually not needed for ASCII\n",
    "    # (The encode('ascii') step is usually enough)\n",
    "\n",
    "    new_len = len(text)\n",
    "    print(f\"Cleaned! Removed {original_len - new_len} bad characters.\")\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    print(f\"Saved clean file to: {output_path}\")\n",
    "\n",
    "# --- RUN IT ---\n",
    "source_file = \"./resources/harrypotter.txt\"       # Your bad file\n",
    "clean_file = \"./resources/harrypotter_clean.txt\"  # The new good file\n",
    "\n",
    "clean_text_nuclear(source_file, clean_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7e7676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved to ./resources/harrypotter_clean.txt\n"
     ]
    }
   ],
   "source": [
    "# Convert text to pure ASCII\n",
    "with open(\"./resources/harrypotter.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Replace common multi-byte chars with single-byte equivalents\n",
    "text = text.replace(\"’\", \"'\")\n",
    "text = text.replace(\"“\", '\"')\n",
    "text = text.replace(\"”\", '\"')\n",
    "text = text.replace(\"—\", \"-\")\n",
    "# Force convert the rest to ASCII, ignoring errors\n",
    "text = text.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "\n",
    "with open(\"./resources/harrypotter_clean.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Cleaned file saved to ./resources/harrypotter_clean.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c19c3d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found: ['text', 'meta']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual csv filename\n",
    "csv_file = \"./data/train.csv\" \n",
    "\n",
    "# Read just the first 5 rows to see the columns\n",
    "df = pd.read_csv(csv_file, nrows=5)\n",
    "print(\"Columns found:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc81de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting total rows (this might take a moment)...\n",
      "Converting 'text' from CSV to TXT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 100000/6558358 [00:04<04:56, 21747.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS!\n",
      "Clean text saved to: ./resources/pile_clean.txt\n",
      "You can now train your tokenizer on this file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ---------------- CONFIGURATION ----------------\n",
    "# Change this to match your actual file name\n",
    "INPUT_CSV = \"/media/danny/SuperMoose/Data/nanoGPT/train.csv\"\n",
    "OUTPUT_TXT = \"/media/danny/SuperMoose/Data/nanoGPT/pile_clean.txt\"\n",
    "TEXT_COLUMN = \"text\"  \n",
    "CHUNK_SIZE = 10000    # Reads 10,000 rows at a time (saves RAM)\n",
    "# -----------------------------------------------\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text to prevent 'Unknown Character' errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Fix the specific characters seen in your snippet\n",
    "    text = text.replace('“', '\"').replace('”', '\"') # Fix: “Survival” -> \"Survival\"\n",
    "    text = text.replace(\"‘\", \"'\").replace(\"’\", \"'\") # Fix: There’s -> There's\n",
    "    text = text.replace('—', '-')\n",
    "    \n",
    "    # 2. Force ASCII (The Nuclear Option)\n",
    "    # This removes any other weird symbols (emojis, chinese chars, etc)\n",
    "    # that your Bigram model cannot handle.\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "def process_csv_to_txt():\n",
    "    if not os.path.exists(INPUT_CSV):\n",
    "        print(f\"Error: Could not find {INPUT_CSV}\")\n",
    "        return\n",
    "\n",
    "    # 1. Count total rows (just for the progress bar display)\n",
    "    print(\"Counting total rows (this might take a moment)...\")\n",
    "    try:\n",
    "        with open(INPUT_CSV, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            total_rows = sum(1 for _ in f) - 1\n",
    "    except:\n",
    "        total_rows = None # If counting fails, just proceed without total\n",
    "        print(\"Could not count rows, proceeding anyway...\")\n",
    "\n",
    "    # 2. Process and Save\n",
    "    print(f\"Converting '{TEXT_COLUMN}' from CSV to TXT...\")\n",
    "    \n",
    "    with open(OUTPUT_TXT, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        # Read CSV in chunks using Pandas\n",
    "        with pd.read_csv(INPUT_CSV, chunksize=CHUNK_SIZE, on_bad_lines='skip') as reader:\n",
    "            \n",
    "            pbar = tqdm(total=total_rows, desc=\"Processing\")\n",
    "            \n",
    "            for chunk in reader:\n",
    "                if TEXT_COLUMN not in chunk.columns:\n",
    "                    print(f\"Error: Column '{TEXT_COLUMN}' not found in this chunk!\")\n",
    "                    continue\n",
    "                \n",
    "                # Convert content to string and clean it\n",
    "                clean_lines = chunk[TEXT_COLUMN].astype(str).apply(normalize_text)\n",
    "                \n",
    "                # Write to file (join documents with two newlines)\n",
    "                f_out.write(\"\\n\\n\".join(clean_lines) + \"\\n\\n\")\n",
    "                \n",
    "                pbar.update(len(chunk))\n",
    "            \n",
    "            pbar.close()\n",
    "\n",
    "    print(\"\\nSUCCESS!\")\n",
    "    print(f\"Clean text saved to: {OUTPUT_TXT}\")\n",
    "    print(\"You can now train your tokenizer on this file.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_csv_to_txt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
